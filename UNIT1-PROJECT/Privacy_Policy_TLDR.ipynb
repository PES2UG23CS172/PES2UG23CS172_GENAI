{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!pip install transformers torch pypdf\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EFkJhcMb-_iA",
        "outputId": "88fbd3ec-3168-4707-deb3-218b325bed62"
      },
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: transformers in /usr/local/lib/python3.12/dist-packages (4.57.6)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.12/dist-packages (2.9.0+cu126)\n",
            "Requirement already satisfied: pypdf in /usr/local/lib/python3.12/dist-packages (6.6.2)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from transformers) (3.20.3)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.34.0 in /usr/local/lib/python3.12/dist-packages (from transformers) (0.36.0)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.12/dist-packages (from transformers) (2.0.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.12/dist-packages (from transformers) (25.0)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.12/dist-packages (from transformers) (6.0.3)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.12/dist-packages (from transformers) (2025.11.3)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.12/dist-packages (from transformers) (2.32.4)\n",
            "Requirement already satisfied: tokenizers<=0.23.0,>=0.22.0 in /usr/local/lib/python3.12/dist-packages (from transformers) (0.22.2)\n",
            "Requirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.12/dist-packages (from transformers) (0.7.0)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.12/dist-packages (from transformers) (4.67.1)\n",
            "Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.12/dist-packages (from torch) (4.15.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.12/dist-packages (from torch) (75.2.0)\n",
            "Requirement already satisfied: sympy>=1.13.3 in /usr/local/lib/python3.12/dist-packages (from torch) (1.14.0)\n",
            "Requirement already satisfied: networkx>=2.5.1 in /usr/local/lib/python3.12/dist-packages (from torch) (3.6.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from torch) (3.1.6)\n",
            "Requirement already satisfied: fsspec>=0.8.5 in /usr/local/lib/python3.12/dist-packages (from torch) (2025.3.0)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.6.80 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.80)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.10.2.21 in /usr/local/lib/python3.12/dist-packages (from torch) (9.10.2.21)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.6.4.1 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.4.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.3.0.4 in /usr/local/lib/python3.12/dist-packages (from torch) (11.3.0.4)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.7.77 in /usr/local/lib/python3.12/dist-packages (from torch) (10.3.7.77)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.7.1.2 in /usr/local/lib/python3.12/dist-packages (from torch) (11.7.1.2)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.5.4.2 in /usr/local/lib/python3.12/dist-packages (from torch) (12.5.4.2)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.7.1 in /usr/local/lib/python3.12/dist-packages (from torch) (0.7.1)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.27.5 in /usr/local/lib/python3.12/dist-packages (from torch) (2.27.5)\n",
            "Requirement already satisfied: nvidia-nvshmem-cu12==3.3.20 in /usr/local/lib/python3.12/dist-packages (from torch) (3.3.20)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.77)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.6.85 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.85)\n",
            "Requirement already satisfied: nvidia-cufile-cu12==1.11.1.6 in /usr/local/lib/python3.12/dist-packages (from torch) (1.11.1.6)\n",
            "Requirement already satisfied: triton==3.5.0 in /usr/local/lib/python3.12/dist-packages (from torch) (3.5.0)\n",
            "Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub<1.0,>=0.34.0->transformers) (1.2.0)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from sympy>=1.13.3->torch) (1.3.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2->torch) (3.0.3)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests->transformers) (3.4.4)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests->transformers) (3.11)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests->transformers) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests->transformers) (2026.1.4)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import files\n",
        "\n",
        "uploaded = files.upload()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 73
        },
        "id": "kfFAqyF2BLh_",
        "outputId": "f087211c-bad0-4703-edf0-f75b4e5f6f55"
      },
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-43bd5933-35ac-4734-a381-871c96393af3\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-43bd5933-35ac-4734-a381-871c96393af3\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script>// Copyright 2017 Google LLC\n",
              "//\n",
              "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
              "// you may not use this file except in compliance with the License.\n",
              "// You may obtain a copy of the License at\n",
              "//\n",
              "//      http://www.apache.org/licenses/LICENSE-2.0\n",
              "//\n",
              "// Unless required by applicable law or agreed to in writing, software\n",
              "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
              "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
              "// See the License for the specific language governing permissions and\n",
              "// limitations under the License.\n",
              "\n",
              "/**\n",
              " * @fileoverview Helpers for google.colab Python module.\n",
              " */\n",
              "(function(scope) {\n",
              "function span(text, styleAttributes = {}) {\n",
              "  const element = document.createElement('span');\n",
              "  element.textContent = text;\n",
              "  for (const key of Object.keys(styleAttributes)) {\n",
              "    element.style[key] = styleAttributes[key];\n",
              "  }\n",
              "  return element;\n",
              "}\n",
              "\n",
              "// Max number of bytes which will be uploaded at a time.\n",
              "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
              "\n",
              "function _uploadFiles(inputId, outputId) {\n",
              "  const steps = uploadFilesStep(inputId, outputId);\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  // Cache steps on the outputElement to make it available for the next call\n",
              "  // to uploadFilesContinue from Python.\n",
              "  outputElement.steps = steps;\n",
              "\n",
              "  return _uploadFilesContinue(outputId);\n",
              "}\n",
              "\n",
              "// This is roughly an async generator (not supported in the browser yet),\n",
              "// where there are multiple asynchronous steps and the Python side is going\n",
              "// to poll for completion of each step.\n",
              "// This uses a Promise to block the python side on completion of each step,\n",
              "// then passes the result of the previous step as the input to the next step.\n",
              "function _uploadFilesContinue(outputId) {\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  const steps = outputElement.steps;\n",
              "\n",
              "  const next = steps.next(outputElement.lastPromiseValue);\n",
              "  return Promise.resolve(next.value.promise).then((value) => {\n",
              "    // Cache the last promise value to make it available to the next\n",
              "    // step of the generator.\n",
              "    outputElement.lastPromiseValue = value;\n",
              "    return next.value.response;\n",
              "  });\n",
              "}\n",
              "\n",
              "/**\n",
              " * Generator function which is called between each async step of the upload\n",
              " * process.\n",
              " * @param {string} inputId Element ID of the input file picker element.\n",
              " * @param {string} outputId Element ID of the output display.\n",
              " * @return {!Iterable<!Object>} Iterable of next steps.\n",
              " */\n",
              "function* uploadFilesStep(inputId, outputId) {\n",
              "  const inputElement = document.getElementById(inputId);\n",
              "  inputElement.disabled = false;\n",
              "\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  outputElement.innerHTML = '';\n",
              "\n",
              "  const pickedPromise = new Promise((resolve) => {\n",
              "    inputElement.addEventListener('change', (e) => {\n",
              "      resolve(e.target.files);\n",
              "    });\n",
              "  });\n",
              "\n",
              "  const cancel = document.createElement('button');\n",
              "  inputElement.parentElement.appendChild(cancel);\n",
              "  cancel.textContent = 'Cancel upload';\n",
              "  const cancelPromise = new Promise((resolve) => {\n",
              "    cancel.onclick = () => {\n",
              "      resolve(null);\n",
              "    };\n",
              "  });\n",
              "\n",
              "  // Wait for the user to pick the files.\n",
              "  const files = yield {\n",
              "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
              "    response: {\n",
              "      action: 'starting',\n",
              "    }\n",
              "  };\n",
              "\n",
              "  cancel.remove();\n",
              "\n",
              "  // Disable the input element since further picks are not allowed.\n",
              "  inputElement.disabled = true;\n",
              "\n",
              "  if (!files) {\n",
              "    return {\n",
              "      response: {\n",
              "        action: 'complete',\n",
              "      }\n",
              "    };\n",
              "  }\n",
              "\n",
              "  for (const file of files) {\n",
              "    const li = document.createElement('li');\n",
              "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
              "    li.append(span(\n",
              "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
              "        `last modified: ${\n",
              "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
              "                                    'n/a'} - `));\n",
              "    const percent = span('0% done');\n",
              "    li.appendChild(percent);\n",
              "\n",
              "    outputElement.appendChild(li);\n",
              "\n",
              "    const fileDataPromise = new Promise((resolve) => {\n",
              "      const reader = new FileReader();\n",
              "      reader.onload = (e) => {\n",
              "        resolve(e.target.result);\n",
              "      };\n",
              "      reader.readAsArrayBuffer(file);\n",
              "    });\n",
              "    // Wait for the data to be ready.\n",
              "    let fileData = yield {\n",
              "      promise: fileDataPromise,\n",
              "      response: {\n",
              "        action: 'continue',\n",
              "      }\n",
              "    };\n",
              "\n",
              "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
              "    let position = 0;\n",
              "    do {\n",
              "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
              "      const chunk = new Uint8Array(fileData, position, length);\n",
              "      position += length;\n",
              "\n",
              "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
              "      yield {\n",
              "        response: {\n",
              "          action: 'append',\n",
              "          file: file.name,\n",
              "          data: base64,\n",
              "        },\n",
              "      };\n",
              "\n",
              "      let percentDone = fileData.byteLength === 0 ?\n",
              "          100 :\n",
              "          Math.round((position / fileData.byteLength) * 100);\n",
              "      percent.textContent = `${percentDone}% done`;\n",
              "\n",
              "    } while (position < fileData.byteLength);\n",
              "  }\n",
              "\n",
              "  // All done.\n",
              "  yield {\n",
              "    response: {\n",
              "      action: 'complete',\n",
              "    }\n",
              "  };\n",
              "}\n",
              "\n",
              "scope.google = scope.google || {};\n",
              "scope.google.colab = scope.google.colab || {};\n",
              "scope.google.colab._files = {\n",
              "  _uploadFiles,\n",
              "  _uploadFilesContinue,\n",
              "};\n",
              "})(self);\n",
              "</script> "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving google_privacy_policy_en.pdf to google_privacy_policy_en (2).pdf\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from pypdf import PdfReader\n",
        "\n",
        "def extract_text_from_pdf(pdf_path):\n",
        "    reader = PdfReader(pdf_path)\n",
        "    text = \"\"\n",
        "    for page in reader.pages:\n",
        "        text += page.extract_text() + \"\\n\"\n",
        "    return text\n",
        "\n",
        "pdf_path = list(uploaded.keys())[0]\n",
        "policy_text = extract_text_from_pdf(pdf_path)\n",
        "\n",
        "print(policy_text[:1000])  # preview\n",
        "\n",
        "# This cell defines a function to extract text from the uploaded PDF file using `pypdf`.\n",
        "# It then calls this function with the uploaded PDF and prints the first 1000 characters of the extracted text as a preview.\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YG5ryUPcBVB8",
        "outputId": "61256f67-e62a-408b-a4d5-6c5bd0aa1b38"
      },
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GOOGLE PRIVACY POLICY\n",
            "When you use our services, you’re trusting us\n",
            "with your information. We understand this is a big\n",
            "responsibility and work hard to protect your\n",
            "information and put you in control.\n",
            "This Privacy Policy is meant to help you understand what information we collect, why we\n",
            "collect it, and how you can update, manage, export, and delete your information.\n",
            "Privacy Checkup\n",
            "Looking to change your privacy settings?\n",
            "Take the Privacy Checkup\n",
            "Effective July 1, 2025 | Archived versions\n",
            "We build a range of services that help millions of people daily to explore and interact with\n",
            "the world in new ways. Our services include:\n",
            "Google apps, sites, and devices, like Search, YouTube, and Google Home\n",
            "Platforms like the Chrome browser and Android operating system\n",
            "Products that are integrated into third-party apps and sites, like ads, analytics, and\n",
            "embedded Google Maps\n",
            "You can use our services in a variety of ways to manage your privacy. For example, you\n",
            "can sign up for a Google Account if you\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import re\n",
        "\n",
        "def clean_text(text):\n",
        "    text = re.sub(r'\\n+', '\\n', text)\n",
        "    text = re.sub(r'\\s+', ' ', text)\n",
        "    return text.strip()\n",
        "\n",
        "policy_text = clean_text(policy_text)\n",
        "print(len(policy_text))\n",
        "\n",
        "# This cell defines a `clean_text` function using regular expressions to remove extra newlines and spaces from the extracted PDF text.\n",
        "# It then applies this cleaning to `policy_text` and prints the length of the cleaned text.\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5gF0FbsEBVSM",
        "outputId": "6cf7b8df-ed37-4161-e1b6-77465aaabfa3"
      },
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "52639\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import pipeline\n",
        "\n",
        "model_name = \"sshleifer/distilbart-cnn-12-6\"  # much faster, same task\n",
        "\n",
        "summarizer = pipeline(\n",
        "    \"summarization\",\n",
        "    model=model_name,\n",
        "    device=-1\n",
        ")\n",
        "\n",
        "# This cell initializes a summarization pipeline from the transformers library, loading the sshleifer/distilbart-cnn-12-6 model.\n",
        "# It also explicitly sets the device to CPU (device=-1) to avoid potential GPU memory issues.\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GT0L4EirBViC",
        "outputId": "21a29702-ed36-4df3-b34f-fc88208f5d30"
      },
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Device set to use cpu\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def chunk_text(text, chunk_size=500):\n",
        "    words = text.split()\n",
        "    chunks = []\n",
        "    for i in range(0, len(words), chunk_size):\n",
        "        chunk = \" \".join(words[i:i + chunk_size])\n",
        "        chunks.append(chunk)\n",
        "    return chunks\n",
        "\n",
        "chunks = chunk_text(policy_text)\n",
        "print(\"Total chunks:\", len(chunks))\n",
        "\n",
        "# This cell defines a chunk_text function to split the long policy_text into smaller chunks of 500 words each.\n",
        "# This is necessary because summarization models have a maximum input length. It then prints the total number of chunks created."
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5tAVpvPSBVw-",
        "outputId": "50d6f5e3-bc1f-418c-9220-da408933bc38"
      },
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Total chunks: 18\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def adaptive_lengths(text):\n",
        "    words = len(text.split())\n",
        "\n",
        "    max_len = max(20, min(60, words // 2))\n",
        "    min_len = max(10, max_len // 2)\n",
        "\n",
        "    return max_len, min_len\n",
        "\n",
        "    # This cell defines a helper function `adaptive_lengths` that calculates dynamic `max_length` and `min_length` for the summarizer based on the word count of each text chunk.\n",
        "    # This helps generate more relevant summaries for varying chunk sizes.\n"
      ],
      "metadata": {
        "id": "Msxku3YNzCn3"
      },
      "execution_count": 47,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "summaries = []\n",
        "\n",
        "for chunk in chunks:\n",
        "    if len(chunk.strip()) < 50:\n",
        "        continue\n",
        "\n",
        "    max_len, min_len = adaptive_lengths(chunk)\n",
        "\n",
        "    out = summarizer(\n",
        "        chunk,\n",
        "        max_length=max_len,\n",
        "        min_length=min_len,\n",
        "        do_sample=False,\n",
        "        truncation=True\n",
        "    )\n",
        "\n",
        "    summaries.append(out[0][\"summary_text\"])\n",
        "\n",
        "    # This cell iterates through each `chunk` of the `policy_text`. For each chunk, it uses the `summarizer` pipeline to generate a summary with adaptive `max_length` and `min_length` calculated by the `adaptive_lengths` function.\n",
        "    # These individual chunk summaries are then collected into the `summaries` list.\n"
      ],
      "metadata": {
        "id": "rue195xOBWAI"
      },
      "execution_count": 48,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import re\n",
        "\n",
        "sentences = re.split(r'(?<=[.!?])\\s+', final_summary)\n",
        "\n",
        "print(\"==== Privacy Policy TL;DR ====\\n\")\n",
        "for i in range(0, len(sentences), 3):\n",
        "    print(\" \".join(sentences[i:i+3]))\n",
        "    print()\n",
        "# This cell takes the final_summary, splits it into sentences, and then prints it out in a more readable 'TL;DR' format.\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JTj4F67I1pNw",
        "outputId": "25a53b1d-f28a-4e3c-c6b9-ab22ddb17d5f"
      },
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "==== Privacy Policy TL;DR ====\n",
            "\n",
            "The Universal Declaration of Human Rights states that people have rights to both privacy and to safety . But discourse around privacy, speech, and safety can sometimes pit these values against each other . For people who use Facebook, Instagram, WhatsApp and Messenger, individual privacy protections must coexist alongside the voice Meta’s Privacy Review offers a process to analyze privacy alongside other safety, security, and integrity concerns .\n",
            "\n",
            "The regulatory environment for privacy, free speech, and safety is shifting . We hope this format creates an open dialogue to discuss what people want out of new and existing Meta services . Meta is committed to reducing bad experiences on our services .\n",
            "\n",
            "The expansion of digital spaces in which we increasingly interact have created new opportunities for bad actors to exploit peoples’ safety, security, and well-being online . For Meta and others that want to decrease these negative experiences online, we The regulatory environment for privacy, free speech, and safety is shifting . Over the past few decades, the world has experienced an exponential increase in the amount of data generated, processed and stored about its global citizens .\n",
            "\n",
            "The meaning of “personal data” has expanded far beyond traditional identifiers The data we use for integrity purposes can include metadata, such as the location of a photo or the date a file was created . A cross-functional team of experts can make decisions about what types of data are most appropriate to use in different safety, security, and integrity scenarios . Hate speech is prohibited on Meta’s family of apps under our Community Standards .\n",
            "\n",
            "The problem of online hate speech is often in the news and top-of-mind for global policymakers . We want to quickly detect and remove it through automation as soon as it is posted . Meta: It is most fair to remove hate speech content when there is a very high likelihood that it is violating, and at a likelihood where our measurement systems find few false positives .\n",
            "\n",
            "Privacy review looks at privacy protective storage options and aims to limit the data stored to only that which is 10 It can be incredibly difficult, without direct information from the subject of an image or video, to know whether or not adult nudity and sexual activity was consensually taken and shared on our platforms . Automation can potentially provide a more privacy-preserving review for people in vulnerable situations . Meta says it must retain certain account data to prevent new account sign-ups and to detect account holders who are repeatedly violating our policies .\n",
            "\n",
            "We believe using relevant personal account data in addition to content is proportionate when protecting children by reducing recidivism . People may be able to retrieve their account with their phone number to get a security code . People can go into their Account Center to change or delete the security phone number that they share with Facebook .\n",
            "\n",
            "By default, IDs are typically stored for 1 year on Facebook . This allows security teams to We have less ability to offer meaningful services if we don’t have information about what is happening to people in the region . When we adjust our existing tools and design new tools for crisis events, we try to balance the need for people to express themselves with the fact that violent rhetoric Meta may not be able to see and intervene in this scenario if people are using encrypted messaging, so we also sent out alerts on Instagram when people get new message requests .\n",
            "\n",
            "Facebook, Instagram, Messenger and WhatsApp continue to evolve with people’s\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def word_count(text):\n",
        "    return len(text.split())\n",
        "\n",
        "def adaptive_summary_limit(input_text):\n",
        "    wc = word_count(input_text)\n",
        "\n",
        "    if wc < 500:\n",
        "        limit = int(wc * 0.25)\n",
        "    elif wc < 2000:\n",
        "        limit = int(wc * 0.18)\n",
        "    else:\n",
        "        limit = int(wc * 0.10)\n",
        "\n",
        "    # safety bounds\n",
        "    limit = max(120, min(limit, 600))\n",
        "    return limit\n",
        "# This cell defines `word_count` and `adaptive_summary_limit` functions. `adaptive_summary_limit` determines an appropriate word limit for the overall final summary based on the length of the original `policy_text`.\n"
      ],
      "metadata": {
        "id": "uGQZGpo7G5Lx"
      },
      "execution_count": 50,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "max_words = adaptive_summary_limit(policy_text)\n",
        "\n",
        "final_summary = \" \".join(summaries)\n",
        "final_summary = \" \".join(final_summary.split()[:max_words])\n",
        "\n",
        "# This cell first calculates the `max_words` for the final summary using `adaptive_summary_limit`. It then concatenates all individual chunk summaries into a single `final_summary` string and truncates it to the calculated `max_words`.\n"
      ],
      "metadata": {
        "id": "2CumyeSJGNin"
      },
      "execution_count": 51,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import re\n",
        "\n",
        "KEYWORDS = [\n",
        "    \"collect\", \"data\", \"information\", \"share\", \"third party\",\n",
        "    \"location\", \"device\", \"cookies\", \"retain\", \"store\",\n",
        "    \"use\", \"advertising\", \"analytics\"\n",
        "]\n",
        "\n",
        "def adaptive_bullet_count(text):\n",
        "    words = len(text.split())\n",
        "    return min(20, max(8, words // 50))\n",
        "\n",
        "def to_bullets(text):\n",
        "    sentences = re.split(r'(?<=[.!?])\\s+', text)\n",
        "\n",
        "    # Prefer sentences with privacy keywords\n",
        "    important = [\n",
        "        s for s in sentences\n",
        "        if any(k in s.lower() for k in KEYWORDS)\n",
        "    ]\n",
        "\n",
        "    max_points = adaptive_bullet_count(text)\n",
        "\n",
        "    selected = important[:max_points] if important else sentences[:max_points]\n",
        "\n",
        "    return \"\\n\".join(f\"- {s.strip()}\" for s in selected)\n",
        "\n",
        "# This cell defines `KEYWORDS` relevant to data privacy and two functions: `adaptive_bullet_count` (to decide how many bullet points to generate) and `to_bullets`\n",
        "# (to convert a given text into a bulleted list,prioritizing sentences containing the defined keywords)."
      ],
      "metadata": {
        "id": "AjmjqCyaGPkM"
      },
      "execution_count": 52,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data_collection_bullets = to_bullets(final_summary)\n",
        "print(\"\\n==== WHAT DATA DO THEY COLLECT? ====\\n\")\n",
        "print(data_collection_bullets)\n",
        "\n",
        "#This cell uses the `to_bullets` function on the `final_summary` to generate a bulleted list of key points related to data collection. It then prints this bulleted list under a clear heading.\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tn0GFUGxGRoP",
        "outputId": "58f076cb-e15c-431b-cf32-2676a9000702"
      },
      "execution_count": 53,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "==== WHAT DATA DO THEY COLLECT? ====\n",
            "\n",
            "- This Privacy Policy is meant to help you understand what information we collect, why we collect it, and how you can update, manage, export, and delete your information .\n",
            "- We collect information to provide better services to all our users .\n",
            "- The information Google collects depends on how you use our services We collect information about the apps, browsers, and devices you use to access Google services .\n",
            "- We also collect the content you create, upload, or receive from others when using our services .\n",
            "- This includes things like email you write and receive, photos and videos you save, docs and spreadsheets Location data we collect depends in part on device and account settings .\n",
            "- Location data includes GPS and other sensor data from your device IP address .\n",
            "- Google also collects information about you from publicly accessible sources .\n",
            "- We use data to build better services .\n",
            "- You can control what information we use to show you ads by visiting your ad settings in My Ad Center .\n",
            "- We use data for analytics and measurement to understand how our services are used .\n",
            "- You have choices regarding the information we collect and how it's used .\n",
            "- Activity on other sites and apps may be associated with your personal information .\n"
          ]
        }
      ]
    }
  ]
}